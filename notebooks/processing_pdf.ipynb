{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a7d832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymupdf4llm\n",
    "import re\n",
    "import json\n",
    "import tqdm\n",
    "import spacy\n",
    "\n",
    "from langdetect import detect # Add to requirements.txt\n",
    "#from itertools import pairwise\n",
    "from unicodedata import normalize\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29a860",
   "metadata": {},
   "source": [
    "https://pypi.org/project/langdetect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4d3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "92f5e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../input_raw/\"\n",
    "OUTPUT_DIR = \"../input_parsed/\"\n",
    "NLP_MODEL = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a2dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    return detect(text)\n",
    "\n",
    "def pre_process_md(md_text_):\n",
    "    md_text = normalize('NFKD', md_text_).encode('ascii','ignore').decode(\"utf-8\")\n",
    "    md_text = re.sub(r'\\n+', '\\n', md_text).strip()\n",
    "    md_text = re.sub(r\"-{3,}\", \"\", md_text).strip()\n",
    "\n",
    "    return md_text\n",
    "\n",
    "def translate_text(text, src_lang, tgt_lang):\n",
    "        all_translated = []\n",
    "\n",
    "        for sentence in tqdm.tqdm(sent_tokenize(text)):\n",
    "            translated = GoogleTranslator(\n",
    "                source=src_lang,\n",
    "                target=tgt_lang\n",
    "            ).translate(sentence)\n",
    "            \n",
    "            all_translated.append(translated)\n",
    "        \n",
    "        return ' '.join(all_translated)\n",
    "\n",
    "def post_process_md(md_text_):\n",
    "    if md_text_ is None:\n",
    "        return None\n",
    "    \n",
    "    md_text = re.sub(r\"\\*{1,}\", \"\", md_text_).strip()\n",
    "    md_text = re.sub(r\"#{1,}\", \"\", md_text).strip()\n",
    "    md_text = re.sub(r\"-\\* \\*\", \"\", md_text).strip()\n",
    "    md_text = re.sub(r\"\\* \\*\", \" \", md_text).strip()\n",
    "    md_text = re.sub(r\"\\n\", \" \", md_text).strip()\n",
    "\n",
    "    return md_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e415b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title(preprocessed_md_text):\n",
    "    pat = r\"^#\\s\\*\\*(.+)\\*\\*\\n\"\n",
    "    match = re.search(pat, preprocessed_md_text)\n",
    "    if match:\n",
    "        return post_process_md(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_authors(preprocessed_md_text):\n",
    "    pat = r\"^###\\s(.+)$\"\n",
    "    authors = [\n",
    "        re.search(pat, preprocessed_md_text, re.MULTILINE).group(1)\n",
    "    ]\n",
    "    return authors\n",
    "\n",
    "def extract_abstract(preprocessed_md_text):\n",
    "    pat = r\"^###\\s\\*Abstract\\.\\s(.+)\\*\"\n",
    "    match = re.search(pat, preprocessed_md_text, re.M)\n",
    "    if match:\n",
    "        return post_process_md(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_sections(preprocessed_md_text):\n",
    "    pat = r\"^##\\s\\*\\*(.+)\\*\\*$\"\n",
    "    section_titles = []\n",
    "    section_contents = []\n",
    "    match_starts = []\n",
    "    match_ends = []\n",
    "\n",
    "    for match in re.finditer(pat, preprocessed_md_text, re.MULTILINE):\n",
    "        section_titles.append(match.group(1))\n",
    "        match_starts.append(match.start())\n",
    "        match_ends.append(match.end())\n",
    "\n",
    "    match_starts = match_starts[1:] + [len(preprocessed_md_text)]\n",
    "\n",
    "    for start, end in zip(match_ends, match_starts):\n",
    "        section_contents.append(post_process_md(preprocessed_md_text[start:end]))\n",
    "\n",
    "    sections = {\n",
    "        title: content\\\n",
    "            for title, content in zip(section_titles, section_contents) \n",
    "    }\n",
    "    return sections\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6db5a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_out_references(sections_dict):\n",
    "    SECTION_NAMES = [\"References\", \"Referencias\"]\n",
    "    numbered_sections = {section_name: section_content\\\n",
    "                         for section_name, section_content in sections_dict.items()}\n",
    "\n",
    "    ref_keys = [key for key in sections_dict.keys() if key in SECTION_NAMES]\n",
    "    if not ref_keys:\n",
    "        return numbered_sections, dict()\n",
    "    \n",
    "    ref_sections = dict()\n",
    "    for key in ref_keys:\n",
    "        ref_sections[key] = numbered_sections.pop(key)\n",
    "\n",
    "    return numbered_sections, ref_sections\n",
    "\n",
    "def concat_sections(sections_dict):\n",
    "    return \"\\n\".join(\n",
    "        [f\"{key}\\n{val}\" for key, val in sections_dict.items()]\n",
    "    )\n",
    "\n",
    "def tokenize_text(postprocessed_text, nlp_model):\n",
    "    tokens = []\n",
    "    for token in nlp_model(postprocessed_text):\n",
    "        tokens.append({\n",
    "            \"token\": token.text,\n",
    "            \"pos\": token.pos_,\n",
    "            \"lemma\": token.lemma_\n",
    "        })\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def post_process_references(referencs_from_sections):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0a49764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_to_template(preprocessed_md_text, nlp_model):\n",
    "    template = {}\n",
    "    template[\"titulo\"] = extract_title(preprocessed_md_text)\n",
    "    template[\"informacoes_url\"] = None\n",
    "    template[\"idioma\"] = detect_language(preprocessed_md_text)\n",
    "    template[\"storage_key\"] = None\n",
    "    template[\"autores\"] = extract_authors(preprocessed_md_text)\n",
    "    template[\"data_publicacao\"] = None\n",
    "    template[\"resumo\"] = extract_abstract(preprocessed_md_text)\n",
    "    template[\"keywords\"] = None\n",
    "\n",
    "    sections_dict = extract_sections(preprocessed_md_text)\n",
    "    numbered_sections, references_dict = split_out_references(sections_dict)\n",
    "    template[\"referencias\"] = list(references_dict.values()).pop() if references_dict else None\n",
    "    \n",
    "    postprocessed_text = concat_sections(numbered_sections)\n",
    "    template[\"artigo_completo\"] = postprocessed_text\n",
    "\n",
    "    token_list = tokenize_text(postprocessed_text, nlp_model)\n",
    "    template[\"artigo_tokenizado\"] = [token.get(\"token\") for token in token_list]\n",
    "    template[\"pos_tagger\"] = [token.get(\"pos\") for token in token_list]\n",
    "    template[\"lema\"] = [token.get(\"lemma\") for token in token_list]\n",
    "\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0c5be00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_template_to_file(template: dict, output_dir: str, fname: str):\n",
    "    full_name = os.path.join(output_dir, fname)\n",
    "    with open(full_name, \"w\", encoding=\"utf-8\") as out:\n",
    "        json.dump(template, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb07823",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_md_texts = []\n",
    "\n",
    "for fname in tqdm.tqdm(os.listdir(INPUT_DIR)):\n",
    "    full_input_fname = os.path.join(INPUT_DIR, fname)\n",
    "    raw_md_text = pymupdf4llm.to_markdown(full_input_fname)\n",
    "    preprocessed_md_text = pre_process_md(raw_md_text)\n",
    "    template = adjust_to_template(preprocessed_md_text, NLP_MODEL)\n",
    "\n",
    "    output_fname = fname.replace(\".pdf\", \".json\")\n",
    "    write_template_to_file(template, OUTPUT_DIR, output_fname)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
